{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Innovative-Sol-Test.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [
        "nTkUeDnEAQtz",
        "5bkEFoVHaq8V",
        "2Vd6I7xoL9J2",
        "qcZa0TZvPAir",
        "eicc49i4PSP7",
        "3MVT2hm_a51C",
        "R1av67mx7ElO",
        "0dAw1yu27JEy"
      ],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyNaLVwUM1GS0YigpH/kkrwS",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/KhizarAziz/Test_Solution/blob/main/Innovative_Sol_Test.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ao6WFVKRFOXF"
      },
      "source": [
        "import numpy as np\n",
        "# from pathlib import Path\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import cv2"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nTkUeDnEAQtz"
      },
      "source": [
        "# **Setup Datasets**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y7OtTEi4ANv7"
      },
      "source": [
        "#Vision\n",
        "!gdown --id 1Gn8A2bfGK80JlYz9IU6GEWQP1NT8Jjgc\n",
        "!unzip -q dataset.zip # unzip zip file"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hB-4Y5G_D2Wq"
      },
      "source": [
        "# NLP\n",
        "!gdown --id 19YsuFeoRQI3CwEV5VvCBWhR5C9y_3xWW\n",
        "!gdown --id 1v-2WODjtFI6QL1XIiGqKr4u82466lRGu"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "znAZ365PEtM8"
      },
      "source": [
        "# **Vision**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5bkEFoVHaq8V"
      },
      "source": [
        "\n",
        "\n",
        "> ## **Imports**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kAviOdpZargE"
      },
      "source": [
        "from keras.layers import Input,Conv2D,BatchNormalization,ReLU,AveragePooling2D,GlobalAveragePooling2D,Dense,Dropout,multiply\n",
        "from keras.models import Model\n",
        "# from keras import regularizers\n",
        "from keras.optimizers import Adam\n",
        "from keras.utils import to_categorical\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.applications.mobilenet import MobileNet\n",
        "# from keras.callbacks import ReduceLROnPlateau"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Vd6I7xoL9J2"
      },
      "source": [
        "\n",
        "\n",
        "> ## **Load & Preprocess Data**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tNI43FCEL9J3"
      },
      "source": [
        "#paths\n",
        "train_dir = '/content/dataset/training_set/'\n",
        "test_dir = '/content/dataset/test_set'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TOQRIhpVL9J3"
      },
      "source": [
        "#params\n",
        "input_shape = (224,224,3)\n",
        "dropout = 0.2\n",
        "batch_size = 32\n",
        "all_categories = [dirname for dirname in os.listdir(train_dir)]\n",
        "out_categories = len(all_categories)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6VNPZiLBL9J3"
      },
      "source": [
        "#functions\n",
        "def get_dataset(base_dir):\n",
        "  onlyfiles = []\n",
        "  for dirpath, dirnames, filenames in os.walk(base_dir):\n",
        "    for filename in [f for f in filenames if f.endswith(\".jpg\")]:\n",
        "      onlyfiles.append([os.path.join(dirpath,filename),dirpath.split('/')[-1]])\n",
        "  random.shuffle(onlyfiles) # generalize better\n",
        "  return onlyfiles\n",
        "\n",
        "def data_generator(onlyfiles,img_shape,batch_size):\n",
        "  df_count = len(onlyfiles)\n",
        "  while True:\n",
        "    start = 0\n",
        "    while start+batch_size < df_count:\n",
        "      current_batch = onlyfiles[start:start+batch_size] # fetching a sub_df, which is our batch\n",
        "      #load imgs, normalize & create a list\n",
        "      img_List = []\n",
        "      train_labels = [] # list for 2_point_rep of ages\n",
        "      for item in current_batch: #iterate over batch to load & transform each img\n",
        "        img = cv2.imread(item[0])\n",
        "        ss = np.min(img.shape[0:2])\n",
        "        img = img[0:ss,0:ss] # crop_square\n",
        "        img = cv2.resize(img,img_shape[0:2])\n",
        "        img = img/255 # normalize\n",
        "        img_List.append(img)\n",
        "        \n",
        "        # labels encoding\n",
        "        label_id = all_categories.index(item[1])\n",
        "        label_enc = to_categorical(label_id,len(all_categories))\n",
        "        train_labels.append(label_enc)\n",
        "\n",
        "      img_np = np.array(img_List) \n",
        "      labels_np = np.array(train_labels)\n",
        "\n",
        "      yield img_np, labels_np # return batch\n",
        "      start += batch_size # update start point, for next batch\n",
        "\n",
        "def get_testset(onlyfiles,img_shape):\n",
        "  imgs = []\n",
        "  labels = []\n",
        "  for item in onlyfiles:\n",
        "    img = cv2.imread(item[0])\n",
        "    # ss = np.min(img.shape[0:2])\n",
        "    # img = img[0:ss,0:ss] # crop_square\n",
        "    img = cv2.resize(img,img_shape[0:2])\n",
        "    img = img/255 # normalize\n",
        "    imgs.append(img)\n",
        "    \n",
        "    # labels encoding\n",
        "    label_id = all_categories.index(item[1])\n",
        "    label_enc = to_categorical(label_id,len(all_categories))\n",
        "    labels.append(label_enc)\n",
        "  img_np = np.array(imgs) \n",
        "  labels_np = np.array(labels)  \n",
        "  return img_np,labels_np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WxihsrZIL9J3"
      },
      "source": [
        "# train & val split\n",
        "dataset = get_dataset(train_dir)\n",
        "trainset, valset = train_test_split(dataset, train_size=0.8, test_size=0.2, random_state=5)\n",
        "train_gen = data_generator(trainset,input_shape ,batch_size)\n",
        "val_gen = data_generator(valset,input_shape ,batch_size)\n",
        "\n",
        "# testset\n",
        "testset = get_dataset(test_dir)\n",
        "test_imgs,test_labels = get_testset(testset,input_shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qcZa0TZvPAir"
      },
      "source": [
        "\n",
        "\n",
        "> ## **Training & Evaluate**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zd0cDdjBL9J3"
      },
      "source": [
        "# MODEL \n",
        "model = MobileNet(include_top=False,weights='imagenet',input_shape=input_shape)\n",
        "m = GlobalAveragePooling2D()(model.output)\n",
        "m = Dense(128,activation='relu')(m)\n",
        "m_out = Dense(out_categories,activation='softmax')(m)\n",
        "model = Model(inputs=[model.input],outputs=[m_out])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zyDYn9sFL9J3"
      },
      "source": [
        "#COMPILE\n",
        "lr = 0.001\n",
        "adam = Adam(lr=lr)\n",
        "model.compile(\n",
        "    optimizer=adam,\n",
        "    loss = 'binary_crossentropy',\n",
        "    metrics='accuracy'\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ONdrZXtnL9J3"
      },
      "source": [
        "epochs = 15\n",
        "history = model.fit(train_gen,steps_per_epoch=len(trainset) / batch_size, epochs=epochs,validation_data=val_gen,  validation_steps=len(valset) / batch_size * 3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8NmDkVjVL9J3"
      },
      "source": [
        "plt.plot(history.history['accuracy'])\n",
        "plt.grid(axis='both')\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.legend(['accuracy', 'val_accuracy'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eicc49i4PSP7"
      },
      "source": [
        "\n",
        "\n",
        "> ## **Inference**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jtIUrXiNL9J3"
      },
      "source": [
        "# prediction\n",
        "p = model.evaluate(test_imgs,test_labels)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m_SW7sjwZszS"
      },
      "source": [
        "print(f'Loss: {p[0]} -  Accuracy: {round(p[1]*100,3)}%')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JrE4zne8aFvU"
      },
      "source": [
        "# **NLP**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3MVT2hm_a51C"
      },
      "source": [
        "\n",
        "\n",
        "> ## **Imports**\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D1jOdZrca51C"
      },
      "source": [
        "import nltk\n",
        "import string\n",
        "import re\n",
        "import keras.backend as K\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.layers import Embedding,Dense,Dropout,LSTM\n",
        "from keras.models import Sequential\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from keras.utils import to_categorical\n",
        "import pandas as pd\n",
        "pd.set_option('display.max_colwidth',100)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R1av67mx7ElO"
      },
      "source": [
        "> ## **Load & Preprocess Data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RSHzNy_jKney"
      },
      "source": [
        "train_df = pd.read_csv('/content/twitter_train.csv',encoding = \"ISO-8859-1\")\n",
        "train_df = train_df[['Sentiment','OriginalTweet']]\n",
        "test_df = pd.read_csv('/content/twitter_test.csv',encoding = \"ISO-8859-1\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Br0RbRJsosIG"
      },
      "source": [
        "#CREATING LABELS\n",
        "def create_labels(data_df):\n",
        "  all_categories = data_df['Sentiment'].unique()\n",
        "  out_categories = len(all_categories)\n",
        "  labels = []\n",
        "  for i in data_df['Sentiment']:\n",
        "    label_id = np.where(all_categories == i)\n",
        "    label_enc = to_categorical(label_id,out_categories)\n",
        "    labels.append(label_enc[0])\n",
        "  return labels\n",
        "\n",
        "labels = np.array(create_labels(train_df))\n",
        "test_labels = np.array(create_labels(test_df))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JHXrsdQTnz_v"
      },
      "source": [
        "#VALIDATIO SPLIT\n",
        "x_train,x_val,y_train,y_val = train_test_split(train_df['OriginalTweet'],labels,test_size=0.2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-8bawqixmbEM"
      },
      "source": [
        "# initialize and fit tokenizer\n",
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(x_train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GljdpvslnDqv"
      },
      "source": [
        "#use tokenizer to trnsfrm txt msgz in training and test sets\n",
        "x_train_seq = tokenizer.texts_to_sequences(x_train)\n",
        "x_test_seq = tokenizer.texts_to_sequences(x_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rbUTHC9IrJPM"
      },
      "source": [
        "# add padding to equalize size of each tweet\n",
        "x_train_seq_padded = pad_sequences(x_train_seq,60)\n",
        "x_test_seq_padded = pad_sequences(x_test_seq,60)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0dAw1yu27JEy"
      },
      "source": [
        "> ## **Training & Evaluation**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L8gkYwlRlv02"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Embedding(len(tokenizer.index_word)+1,32)) # Creating vectors (vectorization inside model) of length 32\n",
        "model.add(LSTM(32,dropout=0,recurrent_dropout=0)) # type of rnn\n",
        "model.add(Dense(32,activation='relu'))\n",
        "model.add(Dense(5,activation='sigmoid'))\n",
        "# model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0U2OEupz7RDj"
      },
      "source": [
        "def recall_m(y_true, y_pred):\n",
        "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
        "    recall = true_positives / (possible_positives + K.epsilon())\n",
        "    return recall\n",
        "\n",
        "def precision_m(y_true, y_pred):\n",
        "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
        "    precision = true_positives / (predicted_positives + K.epsilon())\n",
        "    return precision\n",
        "\n",
        "def f1_m(y_true, y_pred):\n",
        "    precision = precision_m(y_true, y_pred)\n",
        "    recall = recall_m(y_true, y_pred)\n",
        "    return 2*((precision*recall)/(precision+recall+K.epsilon()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "47MyyZsYs2au"
      },
      "source": [
        "model.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics = ['accuracy',precision_m,f1_m]\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UxLc5jyMlMIe"
      },
      "source": [
        "history = model.fit(x_train_seq_padded,y_train,batch_size=32,epochs=10,\n",
        "          validation_data=(x_test_seq_padded,y_test))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aeQRvDdAKn-m"
      },
      "source": [
        "plt.plot(history.history['precision_m'])\n",
        "plt.grid(axis='both')\n",
        "plt.plot(history.history['val_precision_m'])\n",
        "plt.legend(['precision_m', 'val_precision_m'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}